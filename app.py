# app.py (vers√£o revisada)
import streamlit as st
import pandas as pd
import pdfplumber
import re
import requests
from io import BytesIO

st.set_page_config(page_title="Auditor TR - Valida√ß√£o Completa (Revisado)", layout="wide")
st.title("üõ°Ô∏è Auditor TR ‚Äî Extra√ß√£o robusta + Consulta CATMAT")

# -------------------------
# UTILIDADES
# -------------------------
def clean_number(value):
    if value is None or (isinstance(value, float) and pd.isna(value)):
        return 0.0
    text = str(value).upper().replace('R$', '').replace(' ', '').strip()
    text = text.replace('.', '').replace(',', '.')
    clean_str = re.sub(r'[^\d\.]', '', text)
    try:
        return float(clean_str) if clean_str != "" else 0.0
    except:
        return 0.0

def normalize_text(text):
    return str(text).strip() if text else ""

# -------------------------
# CONSULTA API GOV (CATMAT / CATSER)
# -------------------------
@st.cache_data(show_spinner=False)
def consultar_item_governo(codigo):
    codigo = re.sub(r'\D', '', str(codigo))
    if not codigo:
        return {"status_api": "Inv√°lido", "descricao":"", "unidade": "-", "link": ""}

    # Primeiro: tentar materiais
    try:
        url = f"https://compras.dados.gov.br/materiais/v1/materiais.json?codigo={codigo}"
        r = requests.get(url, timeout=5)
        if r.status_code == 200:
            j = r.json()
            lista = j.get("_embedded", {}).get("materiais", [])
            if lista:
                item = lista[0]
                unidade = item.get("unidade_medida") or item.get("unidade") or "-"
                return {
                    "status_api": "Ativo-Material",
                    "descricao": item.get("descricao",""),
                    "unidade": unidade,
                    "link": f"https://catalogo.compras.gov.br/cnbs-web/busca?cod={codigo}"
                }
    except Exception as e:
        # n√£o interrompe; vamos tentar servi√ßo
        pass

    # Segundo: tentar servi√ßos
    try:
        url = f"https://compras.dados.gov.br/servicos/v1/servicos.json?codigo={codigo}"
        r = requests.get(url, timeout=5)
        if r.status_code == 200:
            j = r.json()
            lista = j.get("_embedded", {}).get("servicos", [])
            if lista:
                item = lista[0]
                return {
                    "status_api": "Ativo-Servico",
                    "descricao": item.get("descricao",""),
                    "unidade": item.get("unidade") or "UN",
                    "link": f"https://catalogo.compras.gov.br/cnbs-web/busca?cod={codigo}"
                }
    except:
        pass

    return {"status_api":"N√£o Encontrado", "descricao":"", "unidade":"-", "link": f"https://catalogo.compras.gov.br/cnbs-web/busca?cod={codigo}"}

# -------------------------
# EXTRA√á√ÉO H√çBRIDA (tabelas + texto) COM DETEC√á√ÉO DE GRUPOS E ITENS
# -------------------------
def extract_structured_from_pdf(file_stream):
    """
    Vai tentar extrair:
    - reconhecer linhas de tabela via pdfplumber.extract_tables
    - quando falhar, faz varredura no texto para identificar blocos 'GRUPO' e linhas de item
    - retorna DataFrame com colunas: Grupo, Item, C√≥digo, Descri√ß√£o, Unidade, Qtd, VUnit, VTotal
    """
    pages_text = []
    all_tabular_rows = []
    with pdfplumber.open(file_stream) as pdf:
        for page in pdf.pages:
            text = page.extract_text() or ""
            pages_text.append(text)
            # tenta extrair tabelas (com estrat√©gia por linhas)
            try:
                tables = page.extract_tables(table_settings={"vertical_strategy":"lines", "horizontal_strategy":"lines"})
            except Exception:
                tables = page.extract_tables()
            if tables:
                for t in tables:
                    for r in t:
                        # converte None -> ""
                        row = ["" if c is None else c for c in r]
                        if any(str(x).strip() for x in row):
                            all_tabular_rows.append(row)

    full_text = "\n".join(pages_text)

    # 1) Se extra√ß√£o tabular trouxe linhas com muitos campos (√© uma boa), tenta mapear por cabe√ßalho
    df_from_table = None
    if all_tabular_rows:
        # busca linha de cabe√ßalho - heur√≠stica
        header_idx = None
        for i, row in enumerate(all_tabular_rows[:20]):
            row_lower = " ".join([str(x).lower() for x in row])
            if ("descri" in row_lower and ("qtd" in row_lower or "quant" in row_lower)) or ("catmat" in row_lower or "catser" in row_lower):
                header_idx = i
                break

        if header_idx is not None:
            headers = [str(x).strip() or f"col{i}" for i, x in enumerate(all_tabular_rows[header_idx])]
            data_rows = all_tabular_rows[header_idx+1:]
            df_from_table = pd.DataFrame(data_rows, columns=headers[:len(data_rows[0])])
            # Normalize column names to easier keys
            # We'll still fallback to text parsing later if needed

    # 2) Texto profundo: detectar blocos GRUPO e linhas de itens por padr√£o (mais robusto)
    # Padr√µes:
    # - "GRUPO n - ..." -> define group
    # - item lines: come√ßam com n√∫mero do item (1/2 d√≠gitos) possivelmente seguido de descri√ß√£o, e no final possuem CATMAT (c√≥digos numericos 5-7 d√≠gitos) e pre√ßo unit√°rio e total
    groups = []
    rows_struct = []

    current_group = "Sem Grupo Identificado"

    # quebrar texto por linhas e analisar
    text_lines = []
    for p_text in pages_text:
        for ln in p_text.splitlines():
            ln_stripped = ln.strip()
            if ln_stripped:
                text_lines.append(ln_stripped)

    # detecta grupos e itens
    # regex para detectar "GRUPO" ou "GRUPO X -"
    re_group = re.compile(r"\bGRUPO\s*\d+", flags=re.IGNORECASE)
    # regex para detectar linha com c√≥digo CATMAT (5-7 d√≠gitos) e pre√ßos (valor com v√≠rgula ou ponto)
    re_catmat = re.compile(r"(\d{5,7})")
    # regex para pre√ßos (ex: 1.234,56 ou 1234.56)
    re_price = re.compile(r"(\d{1,3}(?:[\.\,]\d{3})*[\.,]\d{2})")

    # Vamos percorrer as linhas, agregando quando necess√°rio
    i = 0
    while i < len(text_lines):
        ln = text_lines[i]

        # atualiza grupo
        if re_group.search(ln):
            current_group = ln.strip()
            i += 1
            continue

        # tenta achar c√≥digo CATMAT na linha
        cat_match = re_catmat.search(ln)
        if cat_match:
            # tenta captar dados na mesma linha
            codigo = cat_match.group(1)
            # Extrair pre√ßos finais (pega √∫ltimos 2 ocorr√™ncias como unit e total se presentes)
            prices = re_price.findall(ln)
            # extrai quantidades: procurar sequ√™ncia de n√∫meros inteiros (por ex '5 3 0 1 1 0' ) - heur√≠stica
            qtds = re.findall(r"\b\d+\b", ln)
            # descri√ß√£o: parte do in√≠cio at√© onde aparece a unidade/c√≥digo; heur√≠stica: tudo antes do c√≥digo encontrado
            start_desc = ln[:cat_match.start()].strip()
            description = start_desc

            # tentativa melhor: se a linha come√ßar com item n√∫mero (ex: "13 BOROHIDRETO ..."), pega item n√∫mero
            item_num = ""
            m_item = re.match(r"^(\d{1,3})\b", ln)
            if m_item:
                item_num = m_item.group(1)

            # Para caso a linha seja muito curta (s√≥ c√≥digo), agregamos a linha anterior como descri√ß√£o
            if len(description) < 5 and i > 0:
                description = text_lines[i-1]

            # tenta inferir unidade do pdf procurando tokens curtos como FR, SC, AM, UN, G, KG
            unit_search = re.search(r"\b(FR|FRASCO|SC|SACO|AM|UN|UNIDADE|G|GR|KG|MG|L|ML|CX|CAIXA)\b", ln, flags=re.IGNORECASE)
            unidade = unit_search.group(1) if unit_search else ""

            # tenta pegar qtd e vunit/vtotal se poss√≠vel
            v_unit = 0.0
            v_total = 0.0
            qtd_val = 0.0

            # heur√≠stica: √∫ltimos dois pre√ßos identificados -> vunit e vtotal (se existirem)
            if len(prices) >= 2:
                try:
                    v_unit = clean_number(prices[-2])
                    v_total = clean_number(prices[-1])
                except:
                    pass
            elif len(prices) == 1:
                v_unit = clean_number(prices[-1])

            # heur√≠stica para qtd: se houver uma sequ√™ncia de 6 inteiros (ex: 7 4 2 0 1 0) pode ser total e por locais
            if len(qtds) >= 3:
                # pegar o primeiro inteiro razo√°vel >0
                for q in qtds:
                    if int(q) > 0 and len(q) <= 4:
                        qtd_val = float(q)
                        break

            # finalmente registra linha
            rows_struct.append({
                "Grupo": current_group,
                "Item": item_num,
                "C√≥digo": codigo,
                "Descri√ß√£o": description,
                "Unid PDF": unidade,
                "Qtd": qtd_val,
                "V. Unit": v_unit,
                "V. Total PDF": v_total,
                "Linha Origem": ln
            })
            i += 1
            continue

        # se n√£o houver c√≥digo, pode ser continua√ß√£o da descri√ß√£o (concatena com pr√≥xima linha)
        # heur√≠stica: se a linha come√ßa com letra e a pr√≥xima cont√©m c√≥digo, juntamos
        if i+1 < len(text_lines) and re_catmat.search(text_lines[i+1]):
            # juntar com a pr√≥xima e re-testar no pr√≥ximo loop (n√£o consumir agora)
            i += 1
            continue

        i += 1

    # Se extraiu algo via tabela (df_from_table) podemos tentar enriquecer rows_struct com c√≥digos que aparecem no df
    # Mas dado a variedade de layouts, retornamos rows_struct como DataFrame
    if not rows_struct:
        # fallback: se n√£o identificou nada, tenta procurar ANY 5-7 d√≠gitos no full text e criar linhas simples
        fallback = []
        for m in re.findall(r"\b\d{5,7}\b", full_text):
            fallback.append({"Grupo":"Sem Grupo Identificado","Item":"","C√≥digo":m,"Descri√ß√£o":"","Unid PDF":"","Qtd":0,"V. Unit":0,"V. Total PDF":0,"Linha Origem":""})
        return pd.DataFrame(fallback), full_text

    df = pd.DataFrame(rows_struct)
    # Limpeza b√°sica: remover duplicados por (C√≥digo, Descri√ß√£o)
    df = df.drop_duplicates(subset=["C√≥digo","Descri√ß√£o"]).reset_index(drop=True)

    return df, full_text

# -------------------------
# UI
# -------------------------
st.markdown("Envie o PDF do Termo de Refer√™ncia (TR). O sistema tentar√° extrair grupos, itens e c√≥digos CATMAT/CATSER, e far√° consulta ao Compras.gov.br.")
uploaded = st.file_uploader("Upload PDF", type=["pdf"])

if uploaded:
    with st.spinner("Extraindo..."):
        df_items, full_text = extract_structured_from_pdf(uploaded)

    if df_items.empty:
        st.error("N√£o foi poss√≠vel extrair itens automaticamente. Verifique o PDF (scan/imagem) ou envie o arquivo original.")
    else:
        st.success(f"{len(df_items)} itens/linhas extra√≠das (heur√≠stica).")
        # Mostra tabela HTML formatada (usando to_html para manter formata√ß√£o)
        st.subheader("Tabela extra√≠da (visualiza√ß√£o)")
        # monta colunas na ordem amig√°vel
        display_df = df_items[["Grupo","Item","C√≥digo","Descri√ß√£o","Unid PDF","Qtd","V. Unit","V. Total PDF","Linha Origem"]]
        # Exibe como dataframe normal (interativo)
        st.dataframe(display_df, use_container_width=True, height=350)

        # Tamb√©m fornece vers√£o HTML tabulada (mais pr√≥xima do que voc√™ pediu)
        st.markdown("### Vers√£o HTML (para copy/paste)")
        html_table = display_df.to_html(index=False, escape=False)
        st.code(html_table, language='html')

        # Bot√£o para iniciar varredura/consulta GOV
        if st.button("üîé Consultar CATMAT/CATSER no Governo para todos os c√≥digos"):
            # preparar coluna de resultados
            results = []
            progress = st.progress(0)
            for idx, r in df_items.iterrows():
                progress.progress((idx+1)/len(df_items))
                cod = r.get("C√≥digo")
                # chamada de API
                gov = consultar_item_governo(cod)
                # compara√ß√£o simples de unidade
                unid_pdf = normalize_text(r.get("Unid PDF",""))
                unid_gov = normalize_text(gov.get("unidade","-"))
                # status t√©cnico
                if gov["status_api"].startswith("Ativo"):
                    if unid_gov != "-" and unid_pdf and unid_pdf.upper() not in unid_gov.upper():
                        status_tec = "Unid. Divergente"
                    else:
                        status_tec = "OK"
                elif gov["status_api"] == "N√£o Encontrado":
                    status_tec = "N√£o Encontrado"
                else:
                    status_tec = gov["status_api"]

                results.append({
                    "Grupo": r.get("Grupo"),
                    "Item": r.get("Item"),
                    "C√≥digo": cod,
                    "Descri√ß√£o PDF": r.get("Descri√ß√£o"),
                    "Unid PDF": r.get("Unid PDF"),
                    "Qtd": r.get("Qtd"),
                    "V. Unit": r.get("V. Unit"),
                    "V. Total PDF": r.get("V. Total PDF"),
                    "Status T√©cnico": status_tec,
                    "Desc. Oficial (Gov)": gov.get("descricao",""),
                    "Unid. Oficial (Gov)": gov.get("unidade","-"),
                    "Link Gov": gov.get("link","")
                })

            df_res = pd.DataFrame(results)
            st.subheader("Resultado da Consulta (tabela final)")
            # Exibe com link ativo: cria coluna de HTML com anchor
            df_display = df_res.copy()
            df_display["Link Gov"] = df_display["Link Gov"].apply(lambda x: f'<a href="{x}" target="_blank">Abrir</a>' if x else "")

            # mostra como dataframe interativo
            st.dataframe(df_res.drop(columns=["Desc. Oficial (Gov)","Unid. Oficial (Gov)"]), use_container_width=True, height=420)

            # mostra html completo (inclui descri√ß√£o oficial)
            st.markdown("### Tabela Final (HTML com descri√ß√µes oficiais)")
            html_final = df_display.to_html(index=False, escape=False)
            st.code(html_final, language='html')

            # Preparar excel em mem√≥ria (corrige TypeError do streamlit)
            with BytesIO() as buffer:
                with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                    df_res.to_excel(writer, index=False, sheet_name="auditoria")
                    writer.save()
                buffer.seek(0)
                st.download_button(
                    label="‚¨áÔ∏è Baixar relat√≥rio (Excel)",
                    data=buffer.getvalue(),
                    file_name="auditoria_catmat.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

            st.success("Consulta finalizada. Revise as linhas com Status T√©cnico diferente de 'OK'.")

