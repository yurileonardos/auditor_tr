# app.py
"""
Auditor TR - Extra√ß√£o fiel + Consulta CATMAT/CATSER
Vers√£o compat√≠vel com Streamlit Cloud (streamlit.app)
- Corrige problemas comuns de deploy (download Excel em buffer, sem lxml, width="stretch")
- Extra√ß√£o por pdfplumber, heur√≠stica de cabe√ßalho e grupos
- Consulta CATMAT/CATSER via API p√∫blica compras.dados.gov.br
"""

import streamlit as st
import pandas as pd
import pdfplumber
import re
import requests
import io
from datetime import datetime
from bs4 import BeautifulSoup

# --- Config ---
st.set_page_config(page_title="Auditor TR - Extra√ß√£o + CATMAT", layout="wide")
st.title("üõ°Ô∏è Auditor TR ‚Äî Extra√ß√£o fiel + Consulta CATMAT/CATSER")

# ---------- Utilit√°rios ----------
def clean_number(value):
    """Converte textos com formato BR para float. Ex: '1.234,56' -> 1234.56"""
    if value is None:
        return 0.0
    s = str(value).strip()
    # Remove currency R$
    s = s.replace("R$", "").replace("\xa0", " ")
    # Remove thousands dots and convert comma to dot
    s = s.replace(".", "").replace(",", ".")
    # Keep only digits, dot and minus
    s = re.sub(r"[^\d\.\-]", "", s)
    try:
        return float(s) if s != "" else 0.0
    except:
        return 0.0

def normalize_text(v):
    if pd.isna(v):
        return ""
    return str(v).strip()

# ---------- Consulta CATMAT / CATSER (API p√∫blica) ----------
@st.cache_data(show_spinner=False)
def consultar_item_cat(codigo):
    """
    Consulta API p√∫blica compras.dados.gov.br para materiais e servi√ßos.
    Retorna dict: status_api, tipo, codigo, descricao, unidade, link
    """
    code = re.sub(r"\D", "", str(codigo))
    if not code:
        return {"status_api": "Inv√°lido", "codigo": codigo, "descricao": "", "unidade": "-", "link": ""}

    # Tenta materiais
    try:
        url_mat = f"https://compras.dados.gov.br/materiais/v1/materiais.json?codigo={code}"
        resp = requests.get(url_mat, timeout=6)
        if resp.status_code == 200:
            j = resp.json()
            mats = j.get("_embedded", {}).get("materiais", [])
            if mats:
                item = mats[0]
                unidade = item.get("unidade_medida") or item.get("unidade") or "-"
                return {
                    "status_api": "Encontrado-Mat",
                    "tipo": "Material",
                    "codigo": code,
                    "descricao": item.get("descricao", "").strip(),
                    "unidade": unidade,
                    "link": f"https://catalogo.compras.gov.br/cnbs-web/busca?cod={code}"
                }
    except Exception:
        pass

    # Tenta servi√ßos
    try:
        url_srv = f"https://compras.dados.gov.br/servicos/v1/servicos.json?codigo={code}"
        resp = requests.get(url_srv, timeout=6)
        if resp.status_code == 200:
            j = resp.json()
            srvs = j.get("_embedded", {}).get("servicos", [])
            if srvs:
                item = srvs[0]
                unidade = item.get("unidade") or "UN"
                return {
                    "status_api": "Encontrado-Serv",
                    "tipo": "Servico",
                    "codigo": code,
                    "descricao": item.get("descricao", "").strip(),
                    "unidade": unidade,
                    "link": f"https://catalogo.compras.gov.br/cnbs-web/busca?cod={code}"
                }
    except Exception:
        pass

    return {
        "status_api": "NaoEncontrado",
        "tipo": None,
        "codigo": code,
        "descricao": "",
        "unidade": "-",
        "link": f"https://catalogo.compras.gov.br/cnbs-web/busca?cod={code}"
    }

# ---------- Extra√ß√£o e reconstru√ß√£o da tabela ----------
HEADER_KEYWORDS = [
    "item","descr","descricao","unidade","catmat","catser","qtd","quant","quantidade",
    "preco","pre√ßo","unit","unitario","total","s√£o paulo","sp","rio","recife","manaus","caet√©","caete"
]

def guess_header_index(rows):
    """Tenta deduzir o √≠ndice da linha de cabe√ßalho entre as primeiras linhas extra√≠das."""
    for i, row in enumerate(rows[:30]):
        if not any(cell for cell in row):
            continue
        row_text = " ".join([str(x).lower() for x in row if x])
        score = sum(1 for kw in HEADER_KEYWORDS if kw in row_text)
        if score >= 2:
            return i
    return None

def extract_tables_from_pdf(file_stream):
    """
    Usa pdfplumber para extrair linhas tabulares (lista de listas) e texto completo.
    """
    tabular_rows = []
    all_text = ""
    try:
        with pdfplumber.open(file_stream) as pdf:
            for page in pdf.pages:
                text = page.extract_text() or ""
                all_text += text + "\n"
                try:
                    tables = page.extract_tables(table_settings={"vertical_strategy":"lines","horizontal_strategy":"lines"})
                    if not tables:
                        tables = page.extract_tables()
                except Exception:
                    tables = page.extract_tables()
                if tables:
                    for t in tables:
                        for r in t:
                            row = [("" if c is None else c) for c in r]
                            if any(str(x).strip() for x in row):
                                tabular_rows.append(row)
    except Exception as e:
        st.warning("Erro ao abrir PDF com pdfplumber: " + str(e))
    return tabular_rows, all_text

def rebuild_dataframe(tabular_rows, full_text):
    """
    Reconstr√≥i um DataFrame padronizado com colunas:
    Grupo, Item, Descri√ß√£o, Unidade, CATMAT, QTD, S√£o Paulo, Rio de Janeiro, Caet√©, Manaus, Recife, Pre√ßo Unit√°rio (R$), Pre√ßo Total (R$)
    """
    std_cols = ["Grupo","Item","Descri√ß√£o","Unidade","CATMAT","QTD","S√£o Paulo","Rio de Janeiro","Caet√©","Manaus","Recife","Pre√ßo Unit√°rio (R$)","Pre√ßo Total (R$)"]
    if tabular_rows:
        header_idx = guess_header_index(tabular_rows)
        if header_idx is None:
            # fallback: assume header is first non-empty row among top 6
            for i, r in enumerate(tabular_rows[:6]):
                if any(str(x).strip() for x in r):
                    header_idx = i
                    break
        if header_idx is not None and header_idx < len(tabular_rows)-1:
            header_row = [normalize_text(c) for c in tabular_rows[header_idx]]
            headers = []
            for i,h in enumerate(header_row):
                name = h if h else f"col{i}"
                headers.append(name)
            data_rows = tabular_rows[header_idx+1:]
            processed = []
            for r in data_rows:
                row = [("" if c is None else c) for c in r]
                if len(row) < len(headers):
                    row += [""]*(len(headers)-len(row))
                processed.append(row[:len(headers)])
            df = pd.DataFrame(processed, columns=headers)
            # normalize strings
            df = df.applymap(lambda x: normalize_text(x) if isinstance(x, str) else x)
            # rename probable columns to standard names
            ren = {}
            for c in df.columns:
                lc = c.lower()
                if "descr" in lc or "espec" in lc:
                    ren[c] = "Descri√ß√£o"
                elif "cat" in lc or "cod" in lc or "c√≥d" in lc:
                    ren[c] = "CATMAT"
                elif "unid" in lc or re.match(r"^u[np]$", lc):
                    ren[c] = "Unidade"
                elif "qtd" in lc or "quant" in lc:
                    ren[c] = "QTD"
                elif "s√£o paulo" in lc or lc.strip() in ("sp","s√£o paulo","sao paulo"):
                    ren[c] = "S√£o Paulo"
                elif "rio" in lc:
                    ren[c] = "Rio de Janeiro"
                elif "recife" in lc:
                    ren[c] = "Recife"
                elif "manaus" in lc:
                    ren[c] = "Manaus"
                elif "caet√©" in lc or "caete" in lc:
                    ren[c] = "Caet√©"
                elif ("pre√ßo unit" in lc or "preco unit" in lc or ("unit" in lc and "total" not in lc)) or ("valor unit" in lc):
                    ren[c] = "Pre√ßo Unit√°rio (R$)"
                elif ("pre√ßo total" in lc or "preco total" in lc or "valor total" in lc) or (("total" in lc) and ("pre√ßo" in lc or "preco" in lc or "valor" in lc)):
                    ren[c] = "Pre√ßo Total (R$)"
                elif "item" in lc and lc.strip() != "descricao":
                    ren[c] = "Item"
            df = df.rename(columns=ren)
            # ensure all std cols present
            for c in std_cols:
                if c not in df.columns:
                    df[c] = ""
            # attempt simple group detection from full_text
            current_group = "SEM GRUPO"
            # if there are explicit "GRUPO" headings in the text, take the first one as current_group
            match = re.search(r"(GRUPO\s*\d+.*?)\n", full_text, flags=re.IGNORECASE)
            if match:
                current_group = match.group(1).strip()
            df["Grupo"] = current_group
            # reorder to standard
            df = df[["Grupo","Item","Descri√ß√£o","Unidade","CATMAT","QTD","S√£o Paulo","Rio de Janeiro","Caet√©","Manaus","Recife","Pre√ßo Unit√°rio (R$)","Pre√ßo Total (R$)"]]
            # numeric conversion
            for c in ["QTD","Pre√ßo Unit√°rio (R$)","Pre√ßo Total (R$)"]:
                if c in df.columns:
                    df[c] = df[c].apply(clean_number)
            return df
    # Fallback: scan for numeric codes in text and create rows
    rows = []
    codes = list(dict.fromkeys(re.findall(r"\b\d{5,7}\b", full_text)))
    for c in codes:
        rows.append({"Grupo":"SEM GRUPO","Item":"","Descri√ß√£o":"","Unidade":"","CATMAT":c,"QTD":0,"S√£o Paulo":0,"Rio de Janeiro":0,"Caet√©":0,"Manaus":0,"Recife":0,"Pre√ßo Unit√°rio (R$)":0,"Pre√ßo Total (R$)":0})
    if rows:
        return pd.DataFrame(rows)
    # empty
    return pd.DataFrame(columns=std_cols)

# ---------- HTML generation ----------
def generate_grouped_html(df):
    """
    Gera HTML por grupo contendo tabelas (pandas.to_html).
    """
    html_parts = []
    if "Grupo" in df.columns:
        groups = df["Grupo"].fillna("SEM GRUPO").unique().tolist()
    else:
        groups = ["Todos os Itens"]
    for g in groups:
        sub = df[df["Grupo"].fillna("SEM GRUPO")==g].copy()
        html_parts.append(f"<h3>{g}</h3>")
        html_parts.append(sub.to_html(index=False, escape=True))
    return "\n".join(html_parts)

# ---------- UI ----------
st.sidebar.header("Configura√ß√µes")
st.sidebar.markdown("Configura√ß√µes r√°pidas do app")

uploaded = st.file_uploader("üìÇ Envie o TR (PDF)", type=["pdf"])
if not uploaded:
    st.info("Envie o PDF do Termo de Refer√™ncia para iniciar a extra√ß√£o.")
    st.stop()

with st.spinner("Extraindo tabelas do PDF (isso pode levar alguns segundos)..."):
    rows, full_text = extract_tables_from_pdf(uploaded)

with st.spinner("Reconstruindo DataFrame..."):
    df = rebuild_dataframe(rows, full_text)

if df.empty:
    st.error("N√£o foi poss√≠vel extrair itens do PDF automaticamente. Se for um PDF escaneado (imagem), fa√ßa OCR antes de enviar.")
    st.stop()

# Exibe resumo
st.markdown("### ‚úÖ Tabela extra√≠da (pr√©via)")
st.write(f"Linhas: {len(df)} ‚Äî Colunas: {', '.join(df.columns)}")
st.dataframe(df, width="stretch", height=360)

# download HTML e Excel
c1, c2, c3 = st.columns([1,1,1])
with c1:
    if st.button("üìÑ Gerar/baixar HTML tabulado"):
        html_body = generate_grouped_html(df)
        full_html = f"""<!doctype html><html lang='pt-BR'><head><meta charset='utf-8'><title>TR - Tabela</title>
        <style>body{{font-family:Arial}}table{{border-collapse:collapse;width:100%}}th,td{{border:1px solid #bbb;padding:6px}}th{{background:#eee}}</style></head><body>
        <h2>Termo de Refer√™ncia ‚Äî Itens (extra√≠do)</h2>{html_body}</body></html>"""
        st.download_button("‚¨áÔ∏è Baixar HTML", data=full_html.encode("utf-8"), file_name="tabela_final.html", mime="text/html")

with c2:
    if st.button("‚¨áÔ∏è Gerar e baixar Excel consolidado"):
        buffer = io.BytesIO()
        with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
            df.to_excel(writer, sheet_name="Itens", index=False)
        buffer.seek(0)
        st.download_button("‚¨áÔ∏è Baixar Excel", data=buffer.getvalue(), file_name="tabela_final.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

with c3:
    if st.button("üîé Consultar CATMAT para c√≥digos detectados"):
        st.info("Executando varredura ‚Äî aguarde (cada consulta usa a API p√∫blica).")
        # localiza coluna de c√≥digo
        code_col = None
        for c in df.columns:
            if c.lower() in ("catmat","catser","codigo","cod","c√≥d"):
                code_col = c; break
        if not code_col:
            for c in df.columns:
                sample = df[c].astype(str).head(30).tolist()
                if any(re.search(r"\b\d{5,7}\b", s) for s in sample):
                    code_col = c; break
        if not code_col:
            st.error("N√£o localizei uma coluna de c√≥digos (CATMAT/CATSER). Renomeie a coluna ou informe manualmente.")
        else:
            st.info(f"Usando coluna: {code_col}")
            codes = df[code_col].astype(str).fillna("").unique().tolist()
            codes = [re.sub(r"\D","",c) for c in codes if re.search(r"\d{5,7}", str(c))]
            total = len(codes)
            progress = st.progress(0)
            results = []
            for i, code in enumerate(codes):
                progress.progress((i+1)/max(1,total))
                res = consultar_item_cat(code)
                results.append(res)
            df_cat = pd.DataFrame(results)
            # salva Excel com duas abas: Itens + CATMAT
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                df.to_excel(writer, sheet_name="Itens", index=False)
                df_cat.to_excel(writer, sheet_name="CATMAT", index=False)
            buffer.seek(0)
            st.download_button("‚¨áÔ∏è Baixar Excel (Itens + CATMAT)", data=buffer.getvalue(), file_name="auditoria_com_catmat.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
            st.markdown("#### Resultados da consulta CATMAT")
            st.dataframe(df_cat, width="stretch", height=300)

# Checagens matem√°ticas r√°pidas
st.markdown("### ‚ÑπÔ∏è Verifica√ß√µes r√°pidas")
if "QTD" in df.columns and "Pre√ßo Unit√°rio (R$)" in df.columns and "Pre√ßo Total (R$)" in df.columns:
    df_check = df.copy()
    df_check["Total Calculado"] = df_check["QTD"].apply(clean_number) * df_check["Pre√ßo Unit√°rio (R$)"].apply(clean_number)
    df_check["Diff"] = (df_check["Total Calculado"] - df_check["Pre√ßo Total (R$)"].apply(clean_number)).abs()
    df_check["Status Math"] = df_check["Diff"].apply(lambda d: "OK" if d <= 0.1 else "DIVERGENTE")
    problemas = df_check[df_check["Status Math"]!="OK"]
    st.write(f"Linhas com diverg√™ncia matem√°tica: {len(problemas)}")
    if not problemas.empty:
        st.dataframe(problemas[["Item","CATMAT","QTD","Pre√ßo Unit√°rio (R$)","Pre√ßo Total (R$)","Total Calculado","Diff"]], width="stretch", height=260)
else:
    st.info("Colunas QTD e Pre√ßo Unit√°rio/Total n√£o detectadas juntas ‚Äî verifica√ß√£o matem√°tica desativada.")

# Footer com data/hora
st.markdown("---")
st.caption(f"Gerado em {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC")
